{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20262f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 15:50:30,815] A new study created in memory with name: no-name-a1145fd8-3b42-4c8b-82e5-5d53c6c6af9d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71860056ec724aca952be02ecb4852fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.05, 0.06),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:48: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.75, 0.85),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:49: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.9, 1),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 16:07:58,606] Trial 0 finished with value: 5.535149276256561 and parameters: {'max_depth': 8, 'learning_rate': 0.056679046261511316, 'subsample': 0.8222072371851699, 'colsample_bytree': 0.9126245241638805, 'reg_alpha': 3.225577034749856e-06, 'reg_lambda': 2.053015859352387e-05, 'min_child_weight': 7, 'eta': 0}. Best is trial 0 with value: 5.535149276256561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.05, 0.06),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:48: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.75, 0.85),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:49: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.9, 1),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 16:29:17,776] Trial 1 finished with value: 6.637826812267304 and parameters: {'max_depth': 8, 'learning_rate': 0.053366930141497924, 'subsample': 0.7593743881872311, 'colsample_bytree': 0.914454431569996, 'reg_alpha': 1.45823865134872e-06, 'reg_lambda': 0.30918447797807735, 'min_child_weight': 1, 'eta': 0}. Best is trial 0 with value: 5.535149276256561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.05, 0.06),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:48: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.75, 0.85),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:49: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.9, 1),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 16:48:44,881] Trial 2 finished with value: 6.427153921127319 and parameters: {'max_depth': 8, 'learning_rate': 0.057102599192204055, 'subsample': 0.7904486891465465, 'colsample_bytree': 0.9031032255423622, 'reg_alpha': 8.886481689890709e-07, 'reg_lambda': 0.0005241580606337788, 'min_child_weight': 2, 'eta': 0}. Best is trial 0 with value: 5.535149276256561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.05, 0.06),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:48: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.75, 0.85),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:49: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.9, 1),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 17:06:48,800] Trial 3 finished with value: 6.0008597612380985 and parameters: {'max_depth': 8, 'learning_rate': 0.05159204825406145, 'subsample': 0.7686009233917711, 'colsample_bytree': 0.9574989477990986, 'reg_alpha': 0.04110129567347137, 'reg_lambda': 1.1719595868836008e-07, 'min_child_weight': 4, 'eta': 0}. Best is trial 0 with value: 5.535149276256561.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:47: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.05, 0.06),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:48: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.75, 0.85),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:49: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.9, 1),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:50: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\1898248344.py:51: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-20 17:18:38,079] Trial 4 finished with value: 5.8850068807601925 and parameters: {'max_depth': 8, 'learning_rate': 0.052408135147789005, 'subsample': 0.7603358240296186, 'colsample_bytree': 0.9364004885300342, 'reg_alpha': 0.07478785924206888, 'reg_lambda': 0.009019493316585704, 'min_child_weight': 8, 'eta': 0}. Best is trial 0 with value: 5.535149276256561.\n",
      "ðŸ† Mejores parÃ¡metros: {'max_depth': 8, 'learning_rate': 0.056679046261511316, 'subsample': 0.8222072371851699, 'colsample_bytree': 0.9126245241638805, 'reg_alpha': 3.225577034749856e-06, 'reg_lambda': 2.053015859352387e-05, 'min_child_weight': 7, 'eta': 0}\n",
      "ðŸ† Mejor MAE CV: 5.5351\n",
      "[0]\ttrain-mae:1.39875\n",
      "[100]\ttrain-mae:0.14047\n",
      "[200]\ttrain-mae:0.11145\n",
      "[300]\ttrain-mae:0.09337\n",
      "[400]\ttrain-mae:0.07979\n",
      "[500]\ttrain-mae:0.06901\n",
      "[600]\ttrain-mae:0.06104\n",
      "[700]\ttrain-mae:0.05317\n",
      "[800]\ttrain-mae:0.04712\n",
      "[900]\ttrain-mae:0.04155\n",
      "[999]\ttrain-mae:0.03707\n",
      "ðŸ’¾ Modelo optimizado guardado.\n"
     ]
    }
   ],
   "source": [
    "# === BLOQUE â€“ OptimizaciÃ³n de hiperparÃ¡metros XGBoost con Optuna ===\n",
    "\n",
    "# 1) Instalar Optuna (si no lo tienes)\n",
    "# %pip install optuna --quiet\n",
    "\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import os\n",
    "\n",
    "# 2) Carga y preprocesamiento (igual que antes)\n",
    "BASE_OUTPUTS = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\output'\n",
    "FEATURES_DIR = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\features'\n",
    "os.makedirs(BASE_OUTPUTS, exist_ok=True)\n",
    "df = pd.read_pickle(os.path.join(FEATURES_DIR, \"dataset_features_product_id.pkl\"))\n",
    "\n",
    "if 'target' not in df.columns:\n",
    "    df = df.sort_values(['product_id','periodo']).reset_index(drop=True)\n",
    "    df['target'] = df.groupby('product_id')['tn'].shift(-2)\n",
    "df = df[df['target'].notna()].reset_index(drop=True)\n",
    "df['target_log'] = np.log1p(df['target'].clip(lower=0))\n",
    "\n",
    "# Features numÃ©ricas\n",
    "exclude = ['share_total','product_id','n_customers','cat2','cat3',\n",
    "           'period','periodo','prod_start','target','target_log',\n",
    "           'tn','brand','cust_request_qty','cust_request_tn',\n",
    "           'plan_precios_cuidados','sku_size']\n",
    "features = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "# Train/test split temporal\n",
    "max_ord = df['period_ordinal'].max()\n",
    "train = df[df['period_ordinal'] <= max_ord - 2]\n",
    "X_train = train[features]\n",
    "y_train = train['target_log']\n",
    "\n",
    "# 3) DefiniciÃ³n de la funciÃ³n objetivo para Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'reg:squarederror',\n",
    "        'eval_metric': 'mae',\n",
    "        'tree_method': 'hist',\n",
    "        'booster': 'gbtree',\n",
    "        'max_depth': trial.suggest_int('max_depth', 8, 8),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.05, 0.06),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.75, 0.85),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.9, 1),\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-8, 1.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-8, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 5, 8),\n",
    "        'eta': 0.056,\n",
    "        'seed': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "  # ðŸ† Mejores parÃ¡metros: {'max_depth': 8, 'learning_rate': 0.057714246298605575, 'subsample': 0.7743395223702895, 'colsample_bytree': 0.9690773222034035, 'reg_alpha': 0.005001769829321724, 'reg_lambda': 9.046521832898346e-07, 'min_child_weight': 5}\n",
    "#ðŸ† Mejor MAE CV: 5.6827\n",
    "    tss = TimeSeriesSplit(n_splits=5)\n",
    "    maes = []\n",
    "    for train_idx, valid_idx in tss.split(X_train):\n",
    "        X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[valid_idx]\n",
    "        y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[valid_idx]\n",
    "        dtr = xgb.DMatrix(X_tr, label=y_tr)\n",
    "        dval = xgb.DMatrix(X_val, label=y_val)\n",
    "        bst = xgb.train(\n",
    "            params,\n",
    "            dtr,\n",
    "            num_boost_round=1000,\n",
    "            evals=[(dtr, 'train'), (dval, 'valid')],\n",
    "            early_stopping_rounds=50,\n",
    "            verbose_eval=False\n",
    "        )\n",
    "        pred = bst.predict(dval)\n",
    "        maes.append(mean_absolute_error(np.expm1(y_val), np.expm1(pred)))\n",
    "    return np.mean(maes)\n",
    "\n",
    "# 4) Ejecutar la bÃºsqueda\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5, show_progress_bar=True)\n",
    "\n",
    "print(\"ðŸ† Mejores parÃ¡metros:\", study.best_params)\n",
    "print(f\"ðŸ† Mejor MAE CV: {study.best_value:.4f}\")\n",
    "\n",
    "# 5) Reentrenar con los mejores parÃ¡metros y todo el train\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'mae',\n",
    "    'tree_method': 'hist',\n",
    "    'eta': 0.056,\n",
    "    'seed': 42,\n",
    "    'verbosity': 0\n",
    "})\n",
    "\n",
    "dtrain_full = xgb.DMatrix(X_train, label=y_train)\n",
    "final_bst = xgb.train(\n",
    "    best_params,\n",
    "    dtrain_full,\n",
    "    num_boost_round=1000,\n",
    "    early_stopping_rounds=50,\n",
    "    evals=[(dtrain_full,'train')],\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "# 6) Guardar el modelo (opcional)\n",
    "final_bst.save_model(os.path.join(BASE_OUTPUTS, 'xgb_optuna_model.json'))\n",
    "print(\"ðŸ’¾ Modelo optimizado guardado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228cc241",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elisabeth\\AppData\\Local\\Temp\\ipykernel_7548\\3821743242.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test['tn_pred'] = pred_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª TEST MAE:  9.438\n",
      "ðŸ§ª TEST RMSE: 28.013\n",
      "ðŸ’¾ PredicciÃ³n final guardada en: C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\output\\pred_modelo_xgb_optunav4.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import os\n",
    "\n",
    "# 1) Configura rutas\n",
    "BASE_OUTPUTS = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\output'\n",
    "FEATURES_DIR = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\features'\n",
    "MODEL_PATH   = os.path.join(BASE_OUTPUTS, 'xgb_optuna_model.json')\n",
    "\n",
    "# 2) Carga tu DataFrame como antes\n",
    "df = pd.read_pickle(os.path.join(FEATURES_DIR, \"dataset_features_product_id.pkl\"))\n",
    "\n",
    "# 3) Vuelve a hacer exactamente el mismo preprocesamiento y split\n",
    "if 'target' not in df.columns:\n",
    "    df = df.sort_values(['product_id','periodo']).reset_index(drop=True)\n",
    "    df['target'] = df.groupby('product_id')['tn'].shift(-2)\n",
    "\n",
    "df = df[df['target'].notna()].reset_index(drop=True)\n",
    "df['target_log'] = np.log1p(df['target'].clip(lower=0))\n",
    "\n",
    "exclude = ['share_total','product_id','n_customers','cat2','cat3',\n",
    "           'period','periodo','prod_start','target','target_log',\n",
    "           'tn','brand','cust_request_qty','cust_request_tn',\n",
    "           'plan_precios_cuidados','sku_size']\n",
    "features = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "max_ord = df['period_ordinal'].max()\n",
    "train = df[df['period_ordinal'] <= max_ord - 2]\n",
    "test  = df[df['period_ordinal'] >  max_ord - 2]\n",
    "X_test = test[features]\n",
    "\n",
    "# 4) Carga el modelo optimizado\n",
    "bst = xgb.Booster()\n",
    "bst.load_model(MODEL_PATH)\n",
    "\n",
    "# 5) EvaluaciÃ³n en TEST\n",
    "dtest     = xgb.DMatrix(X_test)\n",
    "pred_test = np.expm1(bst.predict(dtest))\n",
    "test['tn_pred'] = pred_test\n",
    "\n",
    "mae_test  = mean_absolute_error(test['target'], pred_test)\n",
    "rmse_test = np.sqrt(mean_squared_error(test['target'], pred_test))\n",
    "print(f\"ðŸ§ª TEST MAE:  {mae_test:.3f}\")\n",
    "print(f\"ðŸ§ª TEST RMSE: {rmse_test:.3f}\")\n",
    "\n",
    "# 6) PredicciÃ³n del ÃšLTIMO PERIODO (Â«outÂ»)\n",
    "df_pred = df[df['period_ordinal'] == max_ord]\n",
    "dpred   = xgb.DMatrix(df_pred[features])\n",
    "out     = pd.DataFrame({\n",
    "    'product_id': df_pred['product_id'],\n",
    "    'tn_pred'   : np.expm1(bst.predict(dpred))\n",
    "})\n",
    "\n",
    "out.to_csv(os.path.join(BASE_OUTPUTS, 'pred_modelo_xgb_optuna.csv'), index=False)\n",
    "print(f\"ðŸ’¾ PredicciÃ³n final guardada en: {os.path.join(BASE_OUTPUTS, 'pred_modelo_xgb_optuna.csv')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
