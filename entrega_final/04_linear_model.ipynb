{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir rutas en Drive\n",
    "BASE_DATOS = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\datasets'\n",
    "BASE_INTERMEDIOS   = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\intermedios'\n",
    "SALIDAS   = r'C:\\Users\\Elisabeth\\Desktop\\MAESTRIA_AUSTRAL\\Labo_III\\labo3-2025v\\entrega_final\\output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga archivo CSVsep=\"\\t\")\n",
    "df = pd.read_csv(os.path.join(BASE_DATOS, \"sell-in.txt\"),sep=\"\\t\")\n",
    "df = df[['product_id', 'periodo', 'tn']]\n",
    "df_limpio = pd.read_csv(os.path.join(BASE_INTERMEDIOS, \"df_limpio_product_id.csv\"),sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos por Product ID\n",
    "df_grouped = (\n",
    "    df.groupby(['product_id', 'periodo'], as_index=False)['tn']\n",
    "      .sum()\n",
    ")\n",
    "\n",
    "df_grouped = df_grouped.sort_values(['product_id', 'periodo'])\n",
    "df_grouped['clase'] = (\n",
    "    df_grouped.groupby('product_id')['tn'].shift(-2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos Lags\n",
    "for lag in range(1, 12):\n",
    "    df_grouped[f'tn_{lag}'] = df_grouped.groupby('product_id')['tn'].shift(lag)\n",
    "# df_grouped[df_grouped['product_id'] == 20089]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Productos con al menos un periodo faltante: 697\n",
      "[20032, 20034, 20036, 20040, 20049, 20060, 20064, 20083, 20085, 20089, 20098, 20104, 20110, 20112, 20126, 20127, 20128, 20130, 20131, 20135, 20141, 20143, 20147, 20149, 20150, 20154, 20156, 20159, 20164, 20170, 20172, 20174, 20186, 20191, 20192, 20195, 20199, 20202, 20203, 20210, 20213, 20214, 20217, 20218, 20221, 20223, 20229, 20236, 20237, 20243, 20245, 20247, 20248, 20257, 20258, 20260, 20261, 20262, 20266, 20274, 20286, 20287, 20293, 20294, 20297, 20298, 20306, 20313, 20318, 20319, 20323, 20331, 20333, 20334, 20337, 20339, 20340, 20343, 20344, 20347, 20348, 20351, 20355, 20363, 20364, 20368, 20369, 20370, 20371, 20373, 20377, 20378, 20387, 20389, 20390, 20391, 20392, 20393, 20395, 20397, 20402, 20403, 20405, 20408, 20414, 20415, 20417, 20420, 20423, 20425, 20426, 20427, 20430, 20431, 20436, 20437, 20439, 20440, 20441, 20442, 20444, 20445, 20446, 20447, 20448, 20451, 20452, 20453, 20455, 20456, 20457, 20458, 20459, 20460, 20461, 20462, 20467, 20468, 20469, 20472, 20475, 20476, 20477, 20478, 20479, 20481, 20486, 20487, 20488, 20489, 20491, 20492, 20494, 20495, 20496, 20498, 20499, 20503, 20504, 20506, 20508, 20510, 20511, 20513, 20514, 20515, 20516, 20521, 20522, 20523, 20525, 20526, 20527, 20528, 20529, 20531, 20533, 20534, 20535, 20537, 20540, 20541, 20542, 20543, 20544, 20545, 20546, 20547, 20548, 20550, 20552, 20553, 20554, 20557, 20558, 20559, 20562, 20564, 20566, 20567, 20569, 20571, 20573, 20574, 20575, 20576, 20577, 20578, 20580, 20581, 20582, 20584, 20587, 20588, 20589, 20590, 20591, 20592, 20593, 20595, 20596, 20598, 20603, 20604, 20607, 20608, 20610, 20611, 20613, 20615, 20616, 20618, 20619, 20620, 20621, 20623, 20624, 20625, 20626, 20627, 20630, 20631, 20633, 20634, 20635, 20638, 20641, 20643, 20646, 20648, 20649, 20650, 20657, 20659, 20662, 20665, 20666, 20667, 20668, 20671, 20673, 20674, 20675, 20679, 20681, 20682, 20686, 20687, 20689, 20690, 20691, 20692, 20694, 20698, 20700, 20703, 20704, 20707, 20709, 20711, 20712, 20716, 20717, 20718, 20719, 20720, 20722, 20723, 20724, 20726, 20727, 20728, 20731, 20732, 20736, 20738, 20741, 20743, 20746, 20747, 20748, 20750, 20752, 20754, 20755, 20757, 20758, 20760, 20762, 20763, 20764, 20766, 20767, 20769, 20770, 20771, 20772, 20774, 20775, 20776, 20777, 20778, 20779, 20782, 20783, 20785, 20786, 20787, 20790, 20791, 20792, 20793, 20794, 20795, 20797, 20798, 20799, 20804, 20805, 20806, 20808, 20809, 20811, 20813, 20814, 20815, 20816, 20817, 20818, 20819, 20822, 20824, 20825, 20827, 20829, 20832, 20833, 20835, 20836, 20837, 20839, 20841, 20844, 20845, 20848, 20851, 20853, 20854, 20855, 20856, 20857, 20858, 20859, 20860, 20861, 20866, 20868, 20869, 20872, 20873, 20874, 20876, 20877, 20878, 20879, 20880, 20881, 20884, 20885, 20886, 20887, 20888, 20890, 20891, 20893, 20895, 20897, 20898, 20899, 20902, 20903, 20904, 20905, 20907, 20908, 20909, 20910, 20912, 20914, 20915, 20917, 20918, 20920, 20923, 20924, 20926, 20927, 20928, 20929, 20930, 20932, 20933, 20936, 20938, 20939, 20940, 20942, 20943, 20944, 20945, 20946, 20951, 20953, 20954, 20955, 20958, 20959, 20962, 20963, 20964, 20966, 20967, 20968, 20969, 20971, 20972, 20975, 20978, 20979, 20980, 20981, 20983, 20984, 20987, 20988, 20989, 20990, 20992, 20993, 20995, 20996, 20997, 20998, 20999, 21001, 21002, 21003, 21006, 21007, 21009, 21010, 21011, 21013, 21015, 21018, 21019, 21020, 21021, 21022, 21023, 21026, 21027, 21029, 21030, 21031, 21033, 21034, 21035, 21036, 21037, 21039, 21040, 21041, 21042, 21043, 21044, 21045, 21046, 21047, 21049, 21050, 21051, 21054, 21056, 21058, 21059, 21061, 21062, 21063, 21064, 21065, 21066, 21067, 21068, 21069, 21070, 21071, 21073, 21074, 21075, 21076, 21078, 21079, 21081, 21082, 21083, 21084, 21085, 21086, 21087, 21090, 21091, 21092, 21093, 21094, 21095, 21096, 21097, 21098, 21099, 21100, 21102, 21105, 21106, 21108, 21109, 21110, 21111, 21112, 21113, 21114, 21116, 21117, 21118, 21119, 21120, 21122, 21124, 21125, 21126, 21128, 21129, 21130, 21133, 21135, 21137, 21140, 21142, 21143, 21144, 21146, 21147, 21148, 21149, 21150, 21151, 21152, 21153, 21154, 21155, 21156, 21157, 21158, 21159, 21160, 21161, 21162, 21163, 21164, 21165, 21167, 21168, 21169, 21170, 21171, 21172, 21173, 21174, 21176, 21178, 21179, 21180, 21184, 21185, 21188, 21189, 21190, 21191, 21193, 21194, 21195, 21196, 21198, 21199, 21200, 21201, 21203, 21206, 21207, 21208, 21209, 21210, 21211, 21212, 21213, 21214, 21215, 21216, 21217, 21219, 21220, 21223, 21224, 21225, 21226, 21227, 21228, 21229, 21230, 21232, 21233, 21234, 21237, 21238, 21239, 21240, 21241, 21242, 21244, 21245, 21246, 21247, 21248, 21249, 21252, 21253, 21256, 21259, 21260, 21261, 21262, 21263, 21264, 21265, 21266, 21267, 21268, 21269, 21270, 21271, 21272, 21273, 21274, 21275, 21276, 21277, 21278, 21279, 21281, 21282, 21283, 21284, 21285, 21286, 21287, 21288, 21289, 21290, 21291, 21292, 21293, 21294, 21295, 21296, 21297, 21298, 21299]\n"
     ]
    }
   ],
   "source": [
    "# 1. Crear el rango completo de periodos\n",
    "periodos_completos = sorted(df_grouped['periodo'].unique())\n",
    "set_periodos = set(periodos_completos)\n",
    "\n",
    "# 2. Crear una lista para guardar los productos con datos faltantes\n",
    "productos_con_faltantes = []\n",
    "\n",
    "# 3. Iterar por producto y verificar si cubre todos los per√≠odos\n",
    "for product_id, grupo in df_grouped.groupby('product_id'):\n",
    "    periodos_producto = set(grupo['periodo'])\n",
    "    if periodos_producto != set_periodos:\n",
    "        productos_con_faltantes.append(product_id)\n",
    "\n",
    "# 4. Mostrar el resultado\n",
    "print(f\"üîé Productos con al menos un periodo faltante: {len(productos_con_faltantes)}\")\n",
    "print(productos_con_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tn: -0.001339\n",
      "tn_1: 0.236558\n",
      "tn_2: 0.178208\n",
      "tn_3: -0.060031\n",
      "tn_4: -0.161875\n",
      "tn_5: -0.007775\n",
      "tn_6: 0.151936\n",
      "tn_7: 0.043933\n",
      "tn_8: 0.142839\n",
      "tn_9: 0.103804\n",
      "tn_10: 0.119211\n",
      "tn_11: 0.073671\n",
      "\n",
      "Intercepto: 0.441467\n",
      "‚úÖ Registros completos: 751\n",
      "üî¢ TN total de completos: 24181.9075\n",
      "‚ùå Registros incompletos: 176\n",
      "üî¢ TN total de incompletos: 2035.15978\n"
     ]
    }
   ],
   "source": [
    "# MODELO\n",
    "magicos = [20002, 20003, 20006, 20010, 20011, 20018, 20019, 20021,\n",
    "           20026, 20028, 20035, 20039, 20042, 20044, 20045, 20046,\n",
    "           20049, 20051, 20052, 20053, 20055, 20008, 20001, 20017,\n",
    "           20086, 20180, 20193, 20320, 20532, 20612, 20637, 20807, 20838]\n",
    "\n",
    "#dataset para entrenamiento\n",
    "train_df = df_grouped[(df_grouped['periodo'] == 201812) & (df_grouped['product_id'].isin(magicos))].copy()\n",
    "\n",
    "features = ['tn'] + [f'tn_{i}' for i in range(1, 12)]\n",
    "train_df = train_df.dropna(subset=['clase'] + features)\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['clase']\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Lista de features usadas\n",
    "features = ['tn'] + [f'tn_{i}' for i in range(1, 12)]\n",
    "\n",
    "# Coeficientes asociados a cada variable\n",
    "for feature, coef in zip(features, model.coef_):\n",
    "    print(f\"{feature}: {coef:.6f}\")\n",
    "\n",
    "# Intercepto del modelo\n",
    "print(f\"\\nIntercepto: {model.intercept_:.6f}\")\n",
    "\n",
    "# Dataset para prediccion\n",
    "test_df = df_grouped[df_grouped['periodo'] == 201912].copy()\n",
    "test_df['complete'] = test_df[features].notna().all(axis=1)\n",
    "\n",
    "# Aplicar modelo solo a registros completos\n",
    "df_complete = test_df[test_df['complete']].copy()\n",
    "df_complete['pred'] = model.predict(df_complete[features])\n",
    "\n",
    "# Calcular promedio para incompletos\n",
    "avg_incompletos = test_df.loc[~test_df['complete'], 'tn'].sum()\n",
    "\n",
    "print(\"‚úÖ Registros completos:\", len(df_complete))\n",
    "print(\"üî¢ TN total de completos:\", df_complete['tn'].sum())\n",
    "print(\"‚ùå Registros incompletos:\", (~test_df['complete']).sum())\n",
    "print(\"üî¢ TN total de incompletos:\", avg_incompletos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(751, 17)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo generado:.../predicciones_productos_clase81.csv\n"
     ]
    }
   ],
   "source": [
    "# === 1. Cargar productos objetivo ===\n",
    "productos_pred = pd.read_csv(os.path.join(BASE_DATOS, \"productos_pred.txt\"), sep=\"\\t\")\n",
    "\n",
    "# === 2. Filtrar df_grouped a periodo 201912 ===\n",
    "test_df = df_grouped[df_grouped['periodo'] == 201912].copy()\n",
    "\n",
    "# === 3. Calcular campo 'complete' (sin nulos en tn, tn_1...tn_11) ===\n",
    "features = ['tn'] + [f'tn_{i}' for i in range(1, 12)]\n",
    "test_df['complete'] = test_df[features].notna().all(axis=1)\n",
    "\n",
    "# === 4. Predecir con regresi√≥n para los completos ===\n",
    "df_complete = test_df[test_df['complete']].copy()\n",
    "df_complete['pred'] = model.predict(df_complete[features])\n",
    "\n",
    "# Nueva estrategia: para cada producto incompleto, usar el promedio de los √∫ltimos 12 meses disponibles (ignorando NaN)\n",
    "df_incomplete = test_df[~test_df['complete']].copy()\n",
    "\n",
    "# Calcular promedio de las columnas tn, tn_1 ... tn_11 en la fila\n",
    "df_incomplete['pred'] = df_incomplete[features].mean(axis=1, skipna=True)\n",
    "df_incomplete['metodo'] = 'promedio_12m'\n",
    "\n",
    "# Marcar m√©todo modelo para los completos\n",
    "df_complete['metodo'] = 'modelo'\n",
    "\n",
    "# Unir completos e incompletos\n",
    "df_pred_todos = pd.concat([df_complete, df_incomplete], axis=0)\n",
    "\n",
    "# === 7. Hacer merge con productos_pred (por product_id)\n",
    "df_final = productos_pred.merge(df_pred_todos[['product_id', 'pred']], on='product_id', how='left')\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(SALIDAS, exist_ok=True)\n",
    "\n",
    "# Guardar CSV\n",
    "df_final.to_csv(\n",
    "    os.path.join(SALIDAS, \"pred_modelo_RL.csv\"),\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Archivo generado:.../pred_modelo_RL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===  Filtrar df_grouped a periodo 201910 ===\n",
    "valid_df = df_grouped[df_grouped['periodo'] == 201910].copy()\n",
    "\n",
    "# === Calcular campo 'complete' (sin nulos en tn, tn_1...tn_11) ===\n",
    "features = ['tn'] + [f'tn_{i}' for i in range(1, 12)]\n",
    "valid_df['complete'] = valid_df[features].notna().all(axis=1)\n",
    "\n",
    "# === Predecir con regresi√≥n para los completos ===\n",
    "df_complete_valid = valid_df[valid_df['complete']].copy()\n",
    "df_complete_valid['tn_pred'] = model.predict(df_complete_valid[features])\n",
    "\n",
    "df_incomplete_valid = valid_df[~valid_df['complete']].copy()\n",
    "df_incomplete_valid['tn_pred'] = df_incomplete_valid[features].mean(axis=1, skipna=True)\n",
    "\n",
    "# Unir completos e incompletos\n",
    "df_pred_valid = pd.concat([df_complete_valid, df_incomplete_valid], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "952"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_valid.head()\n",
    "df_pred_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===  Filtrar df_grouped a periodo 201910 ===\n",
    "valid_df_201912 = df_grouped[df_grouped['periodo'] == 201912].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Aseg√∫rate de que valid_df_201912 s√≥lo tenga product_id y tn real\n",
    "df_real = valid_df_201912[['product_id','tn']].rename(columns={'tn':'tn_real'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Merge en df_pred_valid para traer tn_real\n",
    "df_pred_valid = df_pred_valid.merge(\n",
    "    df_real,\n",
    "    on='product_id',\n",
    "    how='left'    # si alg√∫n product_id de pred no est√° en real, quedar√° NaN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìâ Total Forecast Error (TFE): 0.3020\n"
     ]
    }
   ],
   "source": [
    "# === calcular errores absolutos y relativos ===\n",
    "df_pred_valid['abs_error'] = (df_pred_valid['tn_real'] - df_pred_valid['tn_pred']).abs()\n",
    "df_pred_valid['rel_error'] = df_pred_valid['abs_error'] / df_pred_valid['tn_real']\n",
    "\n",
    "# === Calcular Total Forecast Error (TFE) ===\n",
    "total_error = df_pred_valid['abs_error'].sum()\n",
    "total_sales = df_pred_valid['tn_real'].sum()\n",
    "tfe = total_error / total_sales\n",
    "print(f\"\\nüìâ Total Forecast Error (TFE): {tfe:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id   tn_pred_RL  abs_error_RL\n",
      "0       20001  1260.707460    243.981100\n",
      "1       20002   952.585776    134.722774\n",
      "2       20003   689.528570    202.972720\n",
      "3       20004   470.124722    167.775298\n",
      "4       20005   400.887363    192.357067\n"
     ]
    }
   ],
   "source": [
    "# === Construir el DataFrame resumen con product_id, modelo, tn_pred, abs_error y rel_error ===\n",
    "df_errors = pd.DataFrame({\n",
    "  \n",
    "    'product_id': df_pred_valid['product_id'],\n",
    "    'tn_pred_RL': df_pred_valid['tn_pred'],\n",
    "    'abs_error_RL': df_pred_valid['abs_error']\n",
    "})\n",
    "\n",
    "# 6. Mostrar resultado\n",
    "print(df_errors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar CSV\n",
    "df_errors.to_csv(\n",
    "    os.path.join(SALIDAS, \"error_modelo_RL.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
